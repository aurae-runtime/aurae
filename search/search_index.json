{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#mission","title":"Mission","text":"<p>Aurae is on a mission to be the most loved and effective way of managing workloads on a node. Our hope is that by bringing a better set of controls to a node, we can unlock brilliant higher order distributed systems in the future.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Aurae deploys a memory-safe <sup>1</sup> runtime daemon, process manager, and PID-1 initialization system to remotely schedule processes, containers, and virtual machines as well as set node configurations (e.g., like networking storage).</p> <p>Through system proportioning and enterprise workload isolation techniques, the Aurae open-source project can complement higher order schedulers and control planes (such as Kubernetes) as Aurae supports the usage of multi-tenant workloads and enterprise identities all the way down to the socket layer.</p> <p>Aurae is a proud member of the Nivenly foundation.</p>"},{"location":"#fosdem-2023-presentation","title":"FOSDEM 2023 Presentation","text":"<ul> <li>Slides: Link to presentation</li> <li>Website : Link to abstract</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>STILL IN EARLY DEVELOPMENT! The Aurae project and API can change without notice. Do not run the project in production until further notice!</p> <ul> <li>The Aurae project welcomes contributions of all kinds and sizes.</li> <li>Please read the \"getting involved\" documentation before contributing to the   project.</li> <li>You do not have to know Rust to join the project.</li> </ul> <p>By joining the project in its early stages, you will help to create a milestone contender for corporate distributed systems and automation that will remain accessible to anyone.</p>"},{"location":"#expanded-overview","title":"Expanded Overview","text":"<p>By introducing Aurae cells on top of a Linux kernel the control of each internal runtime process on a given node becomes possible. The auraed runtime maintains ownership of every process by managing everything from PID-1 to nested processes.</p> <p>Maintainable and predefined .proto-files contribute to the core definition of the distributed systems runtime and the standard library. During the build process, these .proto-files can allow for greater customization possibilities. The TypeScript file format replaces static manifests (like the YAML file format) for direct interactions with a running system.</p> Auraed To ensure memory safety, Aurae serves the generic system's runtime daemon ([auraed]). AuraeScript The AuraeScript (a Turing-complete scripting language built on TypeScript) library automatically generates itself from the pre-defined .proto files defined in the Aurae standard library.It also directly embeds Deno source code to provide an SDK and the functionality to attach remote clients for the direct remote communication with Aurae. <pre><code>#!/usr/bin/env auraescript\nlet cells = new runtime.CellServiceClient();\n\nlet allocated = await cells.allocate(&lt;runtime.AllocateCellRequest&gt;{\n  cell: runtime.Cell.fromPartial({\n    name: \"my-cell\",\n    cpus: \"2\",\n  }),\n});\n\nlet started = await cells.start(&lt;runtime.StartExecutableRequest&gt;{\n  executable: runtime.Executable.fromPartial({\n    cellName: \"my-cell\",\n    command: \"sleep 4000\",\n    description: \"Sleep for 4000 seconds\",\n    name: \"sleep-4000\",\n  }),\n});\n</code></pre> Authentication Aurae extends SPIFFE/SPIRE (x509 mTLS)-backed identity, authentication (authn), and authorization (authz) in a distributed system down to the Unix domain socket layer. Principle of Least Awareness A single Aurae instance has no awareness of higher order scheduling mechanisms such as the Kubernetes control plane. Runtime Workloads The Aurae runtime API can manage virtual machines, executables, cells, pods, and other spawned Aurae instances. The Aurae Standard Library The Aurae project exposes its functionality as a gRPC API through the Aurae standard library. The V0 API reference contains the current library definition. <ol> <li> <p>The reliability and effectiveness of the Rust systems language make it an excellent choice for the development of the Aurae project. Learn more about Rust \u21a9</p> </li> </ol>"},{"location":"build/","title":"Building Aurae from Source","text":"<p>Checkout the core aurae repository.</p> <p>Note: Aurae currently only targets support for Linux on X86 architecture.</p> <pre><code>https://github.com/aurae-runtime/aurae.git\n</code></pre>"},{"location":"build/#dependencies","title":"Dependencies","text":"<p>The Aurae environment has certain dependencies that are expected to be available. Some of them can be installed via commands provided below.</p> <ul> <li>Rust</li> <li>Protocol Buffer Compiler</li> <li>buf</li> <li>musl libc</li> <li>BPF Linker</li> </ul>"},{"location":"build/#ubuntu","title":"Ubuntu","text":"<pre><code>sudo apt-get install -y protobuf-compiler; # Protocol Buffer Compiler\nsudo apt-get install -y musl-tools; # musl libc\nsudo apt-get install -y build-essential; # gcc compiler\n</code></pre>"},{"location":"build/#fedora","title":"Fedora","text":"<pre><code>sudo dnf install -y protobuf-compiler; # Protocol Buffer Compiler\nsudo dnf install -y musl-gcc; # musl libc\nsudo dnf install -y '@Development Tools'; # gcc compiler\n</code></pre>"},{"location":"build/#arch","title":"Arch","text":"<pre><code>yay -S protobuf # Protocol Buffer Compiler\nyay -S buf # buf\nyay -S musl # musl libc \nyay -S gcc # gcc compiler\n</code></pre>"},{"location":"build/#prepare-the-environment","title":"Prepare the Environment","text":"<p>First you will need to create authentication certificates and create an <code>~/.aurae/config</code> file.</p> <pre><code>make pki config # For quick-start only\n</code></pre> <p>Now you can compile and install the toolchain</p> <pre><code>make all\n</code></pre> <p>You can optionally compile and install each binary directly. E.g.,:</p> <pre><code>make auraed      # compile and install auraed with cargo\nmake auraescript # compile and install auraescript with cargo\n</code></pre> <p>For more commands, and the dependencies between them, please see the Makefile at the root of the repository.</p>"},{"location":"certs/","title":"Generating Client Certificate Material","text":"<p>For an easy start for managing certificate material you can leverage the convenient make target.</p> <pre><code>make pki config\n</code></pre> <p>Which uses the scripts in /hack to self sign X509 certificates with mock identities. </p>"},{"location":"certs/#creating-clients","title":"Creating Clients","text":"<p>After the initial PKI has been generated using the above <code>make pki</code> command, clients can easily be created using the following.</p> <pre><code>./hack/certgen-client &lt;name&gt;\n</code></pre> <p>Where <code>&lt;name&gt;</code> is a unique string for your client you wish to provide authentication material for.</p>"},{"location":"contributors/","title":"File moved","text":"<p>Please click here to see the new file location</p>"},{"location":"quickstart/","title":"Aurae Quickstart","text":"<p>Now that you have built Aurae from source you can begin using Aurae.</p>"},{"location":"quickstart/#running-the-daemon","title":"Running the Daemon","text":"<p>Aurae will run on any system, even if <code>systemd</code> or another init daemon is currently active. </p> <pre><code>sudo -E auraed -v\n</code></pre>"},{"location":"quickstart/#running-your-first-cell","title":"Running your first Cell","text":"<p>All executables in Aurae are ran in an Aurae cell which is just an isolation boundary for a regular executable to run in.</p> <p>Take the following example code which will create a new cell called <code>sleeper-cell</code> which runs with a small CPU quota (time allowed for the process to execute in) and only has access to 2 of the available cores on your system.</p> <pre><code>// create-cell.ts\nimport * as aurae from \"../auraescript/gen/aurae.ts\";\nimport * as cells from \"../auraescript/gen/cells.ts\";\n\nlet client = await aurae.createClient();\nlet cellService = new cells.CellServiceClient(client);\n\nlet allocated = await cellService.allocate(&lt;cells.CellServiceAllocateRequest&gt;{\n    cell: cells.Cell.fromPartial({\n        name: \"sleeper-cell\",\n        cpu: cells.CpuController.fromPartial({\n            weight: 2, // Percentage of CPUs\n            max: 400 * (10 ** 3), // 0.4 seconds in microseconds\n        }),\n    })\n});\nconsole.log('Allocated:', allocated)\n</code></pre> <p>The script can be executed locally against a running <code>auraed</code> daemon as long as you have certificates installed and configured properly. You do so by using <code>auraescript</code>:</p> <pre><code>auraescript ./create-cell.ts\n</code></pre> <p>Once a cell is allocated it will continue to reserve the required resources and persist until the system is rebooted or until another action destroys the cell. </p> <p>Once a cell is created, any amount of nested executables can be executed directly inside the cell. All executables inside a given cell have access to other executables network, storage, and process communication.</p> <pre><code>// run-sleep-in-cell.ts\nimport * as aurae from \"../auraescript/gen/aurae.ts\";\nimport * as cells from \"../auraescript/gen/cells.ts\";\n\nlet client = await aurae.createClient();\nlet cellService = new cells.CellServiceClient(client);\n\nlet started = await cellService.start(&lt;cells.CellServiceStartRequest&gt;{\n    cellName: \"ae-sleeper-cell\",\n    executable: cells.Executable.fromPartial({\n        command: \"/usr/bin/sleep\",\n        args: [\"42\"],\n        description: \"Sleep for 42 seconds\",\n        name: \"sleep-42\"\n    })\n})\nconsole.log('Started:', started)\n</code></pre> <p>Execute the script again with</p> <pre><code>auraescript ./run-sleep-in-cell.ts\n</code></pre> <p>Note that in this example the command tries to sleep for longer than the quota allows, and thus is terminated by the kernel.</p> <p>Think this was fun? You can find more examples in the example directory of github.com/aurae-runtime/aurae/.</p>"},{"location":"signals/","title":"Signals","text":"<p>The Aurae project calls out general rules for how all daemons (including <code>auraed</code> itself) should respond to various POSIX signals. </p> <p>The <code>auraed</code> daemon will proxy signals sent to nested cells and nested <code>auraed</code> instances.</p> Signal Value Proxy Description SIGKILL 9 SIGKILL The most destructive signal. Will immediately kill <code>auraed</code>. SIGHUP 1 SIGHUP Sent when a controlling shell, or TTY is closed. Used to reload <code>auraed</code> and reopen file descriptors. SIGTERM 15 SIGTERM Used to tell a nested <code>auraed</code> it is time to \"die nicely\" and begin stopping workloads in the cache, and destroying nested resources. SIGINT 2 SIGINT Ignored by <code>auraed</code>"},{"location":"signals/#observe-signals-with-auraed-ebpf","title":"Observe signals with auraed eBPF","text":"<pre><code>aer observe get-posix-signals-stream\n</code></pre>"},{"location":"auraed/","title":"Aurae Daemon","text":"<p>The Aurae Daemon (auraed) is the main daemon that powers Aurae.</p> <p>The Aurae Daemon runs as a gRPC server which listens over a Unix domain socket by default.</p> <pre><code>/var/run/aurae/aurae.sock\n</code></pre>"},{"location":"auraed/#running-auraed","title":"Running auraed","text":"<p>Running as <code>/sbin/init</code> is currently under active development.</p> <p>To run auraed as a standard library server you can run the daemon alongside your current init system.</p>"},{"location":"auraed/#building-from-source","title":"Building from source","text":"<p>We suggest using the aurae repository for building all parts of the project.</p> <p>If you intend on building this repository directly you can leverage the Makefile in this repository:</p> <pre><code>make auraed\n</code></pre> <p>or use Cargo directly:</p> <pre><code>cargo clippy\ncargo install --debug --path .\n</code></pre>"},{"location":"auraed/#running-auraed-in-a-container","title":"Running auraed in a Container","text":"<p>It is possible to run auraed in a container as long as the following is considered:</p> <ul> <li>Populating mTLS certificate material into the container.</li> <li>Exposing either the socket or a network interface from the container for client connections.</li> </ul> <p>Building the container (replace with your values):</p> <pre><code>sudo -E docker build -t krisnova/aurae:latest -t krisnova/aurae:$sha -f images/Dockerfile.nested .\nsudo -E docker push krisnova/aurae:latest\nsudo -E docker push krisnova/aurae:$sha\n</code></pre> <p>Running the container as PID 1:</p> <p>Note: This pattern (and the <code>krisnova</code> registry) will never be officially supported by the project. This is temporary as with bootstrap the project.</p> <pre><code>make pki config\nsudo -E docker run -v /etc/aurae:/etc/aurae krisnova/aurae:latest\n</code></pre>"},{"location":"auraed/philosophy/","title":"Aurae Daemon Philosophy","text":""},{"location":"auraescript/","title":"Index","text":"<p>Aurae offers a Turing complete scripting language built on top of TypeScript called AuraeScript. AuraeScript embeds the Deno source code directly, and offers a remote client and SDK to interface directly with Aurae remotely. The AuraeScript library is automatically generated from the <code>.proto</code> files defined in the Aurae Standard Library.</p> <p>Valid TypeScript files can be leveraged to replace static manifests, as well as interact directly with a running system.</p> <pre><code>#!/usr/bin/env auraescript\nlet cells = new runtime.CellServiceClient();\n\nlet allocated = await cells.allocate(&lt;runtime.AllocateCellRequest&gt;{\n    cell: runtime.Cell.fromPartial({\n        name: \"my-cell\",\n        cpus: \"2\"\n    })\n});\n\nlet started = await cells.start(&lt;runtime.StartExecutableRequest&gt;{\n    executable: runtime.Executable.fromPartial({\n        cellName: \"my-cell\",\n        command: \"sleep 4000\",\n        description: \"Sleep for 4000 seconds\",\n        name: \"sleep-4000\"\n    })\n})\n</code></pre> <p>See the Full list of working examples for more!</p>"},{"location":"blog/2022-10-24-aurae-cells/","title":"Workload Isolation with Aurae Cells","text":""},{"location":"blog/2022-10-24-aurae-cells/#runtime-subsystem","title":"Runtime Subsystem","text":"<p>Last week we merged Pull Request #73 which marks the project's formal acceptance of our initial runtime subsystem API.</p> <pre><code>service Runtime {\n\n  rpc RunExecutable(Executable) returns (ExecutableStatus) {}\n\n  rpc RunCell(Cell) returns (CellStatus) {}\n\n  rpc RunVirtualMachine(VirtualMachine) returns (VirtualMachineStatus) {}\n\n  rpc Spawn(Instance) returns (InstanceStatus) {}\n\n  rpc RunPod(Pod) returns (PodStatus) {}\n\n}\n</code></pre> <p>The runtime subsystem is the most fundamental API for Aurae. The API is synchronous, and is intended to serve as the lowest level building block for future subsystems in the project.</p> <p>The API introduces 5 workloads types of runtime isolation primitives, as well as a special function known as <code>Spawn()</code>. </p> <p>The 5 workload types:</p> <ul> <li>Executable</li> <li>Cell</li> <li>VirtualMachine</li> <li>Instance</li> <li>Pod</li> </ul> <p>Thank you to the many authors, contributors, and maintainers who helped the project form conviction on the initial API: </p> <p>Dominic Hamon    | @future-highway  | Hazel Weakly    | Josh Grant    | Malte Janduda    | @taniwha3  | Vincent Riesop   |</p>"},{"location":"blog/2022-10-24-aurae-cells/#keeping-pods-intuitive","title":"Keeping Pods Intuitive","text":"<p>We make the assumption that most Aurae consumers will be interested in \"scheduling pods\", as this is the primary unit of work for Kubernetes.</p> <p>Therefore, we knew we wanted to make Pods look and feel as much like Kubernetes as possible, so they would be intuitive for users.  From a client perspective an Aurae pod should look, feel, and behave just like an OCI compliant Kubernetes pod with only a few small differences.</p> <p>Aurae pods will run with an extra layer of isolation. This isolation is based on virtualization (when applicable) and resembles how Kata containers are created or how firecracker creates a jailed isolation zone.</p> <p>How Aurae manages and builds this isolation zone for pods is what has influenced the runtime API that you see above.</p>"},{"location":"blog/2022-10-24-aurae-cells/#back-to-the-basics-cgroups-and-namespaces","title":"Back to the Basics: cgroups and namespaces","text":"<p>In order to understand the 5 workload types we need a small lesson in cgroups and namespaces.</p>"},{"location":"blog/2022-10-24-aurae-cells/#control-groups-cgroups","title":"Control Groups (cgroups)","text":"<p>A control group or \"cgroup\" for short is a way of \"slicing\" a part of a Linux system into smaller units which can be used for whatever you want. For example, you can cordon off 10% of your systems compute and memory resources with a cgroup, and run any process you want inside it. If your workload eats up more than 10% of the allocated resources, the kernel will terminate it. This cgroup behavior is likely the root cause of many of the <code>OOMKilled</code> and CPU throttling errors you see in Kubernetes today.</p> <p>Notably there are 2 types of cgroup implementation: v1 and v2. Aurae will use the v2 standard by default.</p>"},{"location":"blog/2022-10-24-aurae-cells/#namespaces","title":"Namespaces","text":"<p>A namespace is a way of sharing or isolating specific parts of a Linux system with a process. If all namespaces are shared a process is as close as possible to the \"host\" it runs on. If no namespaces are shared a process is as isolated as possible from the \"host\" it runs on. Exposing namespaces is usually how container escapes are performed, and how lower level networking and storage is managed with Kubernetes.</p> <pre><code>[root@alice]: ls /proc/1/ns\ncgroup  ipc  mnt  net  pid  pid_for_children  time  time_for_children  user  uts\n</code></pre>"},{"location":"blog/2022-10-24-aurae-cells/#containers","title":"Containers","text":"<p>I often say that cgroups are \"vertical\" resource slices and namespaces are \"horizontal\" access controls. When a cgroup is run in its own namespaces it's both a slice of resources, and an isolation boundary as well. We call this intersection a \"container\".</p>"},{"location":"blog/2022-10-24-aurae-cells/#systemd-slices","title":"Systemd Slices","text":"<p>By default, systemd schedules all of its workloads in their own cgroup with access to the same namespaces as PID 1 on the system. These workloads are called services or units.</p> <p>Interestingly enough, Kubernetes also leverages systemd slices. You can usually see both systemd slices (<code>system.slice</code>) and Kubernetes pods (<code>kubepods.slice</code>) running side-by-side by exploring /sys or <code>sysfs(5)</code> on your system. There are usually other cgroups running there as well. </p> <pre><code>[root@alice]: /sys/fs/cgroup&gt;# ls -d */\ndev-hugepages.mount//  kubepods.slice//                 sys-kernel-config.mount//   system.slice//\ndev-mqueue.mount//     pids//                           sys-kernel-debug.mount//    user.slice//\ninit.scope//           sys-fs-fuse-connections.mount//  sys-kernel-tracing.mount//\n</code></pre>"},{"location":"blog/2022-10-24-aurae-cells/#simplifying-the-stack","title":"Simplifying the Stack","text":"<p>We know we wanted to simplify how workloads are managed at scale. We believe that standardizing process management and cgroup management is a way to simplify runtime complexity, as well as offer a means to an ends with the noisy neighbor problem in multi tenant systems.</p> <p>Therefore, we knew we wanted Aurae to offer functionality that would allow it to manage cgroups well for a plethora of runtime use cases and not just containers.</p> <p>In Kubernetes a user needs to understand the nuance of cgroup implementation detail, systemd scheduling semantics, systemd cgroup drivers, 1 of many container runtimes, CNI, CSI, and more in order to cordon off and network a section of their system.</p> <p>With Aurae a user only needs awareness of a single binary which will safely do all of the above in a secure way by default.</p>"},{"location":"blog/2022-10-24-aurae-cells/#introducing-aurae-cells","title":"Introducing Aurae Cells","text":"<p>An Aurae Cell is just a group of processes running in a unique cgroup with explicit deny-by-default access to host namespaces.</p> <p>Additionally, the processes running in a cell will share namespaces, which mirrors how Kubernetes runs containers in a pod. This implies that processes will be able to communicate over the Linux loopback interface (localhost), and share storage between them.</p> <p>These processes can be grouped together and executed beside each other. Most users will recognize this pattern as the pattern that has enabled the sidecar pattern.</p> <p></p> <p>Because Aurae intends to manage every process on a system, Aurae will be able to make trustworthy guarantees and offer expressive controls over how a host is broken into cells.</p> <p></p>"},{"location":"blog/2022-10-24-aurae-cells/#executables","title":"Executables","text":"<p>Aurae will be able to execute regular old shell processes in a cell. We call these each of these basic processes an <code>Executable</code>.</p> <pre><code>  rpc RunExecutable(Executable) returns (ExecutableStatus) {}\n</code></pre>"},{"location":"blog/2022-10-24-aurae-cells/#container-cells","title":"Container Cells","text":"<p>Additionally, Aurae will be able to execute OCI compliant container images in a cell which we just call a <code>Cell</code>.</p> <pre><code>  rpc RunCell(Cell) returns (CellStatus) {}\n</code></pre> <p>Regardless of if an administrator is executing a basic process, or a container: Aurae will manage the underlying cgroup and namespace implementation.</p>"},{"location":"blog/2022-10-24-aurae-cells/#introducing-virtualization","title":"Introducing Virtualization","text":"<p>Taking a step back from containerization we also understand that many enterprise users will need to execute untrusted code at scale. Aurae additionally acts as a lightweight virtualization hypervisor and meta-data service in addition to being a cgroup broker.</p> <p>Each instance of Aurae comes with its own running PID 1 daemon called <code>auraed</code>.</p> <p></p>"},{"location":"blog/2022-10-24-aurae-cells/#understanding-virtualization","title":"Understanding Virtualization","text":"<p>Virtualization is a more secure level of isolation that operates closer to the hardware. The boundary between a host and a guest virtualized workload is layer 3 of networking, and block patterns in storage. This more abstract interface creates a much more resilient environment for executing a workload.</p> <pre><code>  rpc RunVirtualMachine(VirtualMachine) returns (VirtualMachineStatus) {}\n</code></pre>"},{"location":"blog/2022-10-24-aurae-cells/#microvms-with-aurae","title":"MicroVMs with Aurae","text":"<p>Aurae brings the short-lived, destroy on exit (MicroVM) paradigm into scope by embedding the firecracker Rust crates directly and scheduling workloads with the KVM or Kernel-based Virtual Machine.</p> <p>Aurae is able to <code>Spawn()</code> a new <code>Instance</code> of itself into a newly created MicroVM which can be used arbitrarily.</p>"},{"location":"blog/2022-10-24-aurae-cells/#aurae-spawn","title":"Aurae Spawn","text":"<p>The name <code>Spawn()</code> is taken from the Rust <code>std::process</code> crate and resembles a pattern what most Linux users will know as <code>unshare(2)</code> or namespace delegation. Basically a spawned instance of Aurae will inherit certain properties from the parent, and will come with a few basic guarantees with regard to security and connectivity.</p> <p>Aurae is designed to be recursive, which enables nested isolation zones and gives the project the basic building blocks it needs to hold an opinion on how users should run workloads.</p> <p>Spawned Aurae instances will receive a bridged TAP network device which a nested <code>auraed</code> daemon will listen on by default. This allows a parent Aurae instance running with an independent kernel to communicate directly with a child instance over the same mTLS authenticated gRPC API the rest of the project leverages.</p> <pre><code>  rpc Spawn(Instance) returns (InstanceStatus) {}\n</code></pre> <p>Aurae will manage creating an ephemeral SPIFFE service identity for each spawned instance and will delegate down kernel images, <code>initramfs</code>, and even the <code>auraed</code> daemon itself.</p> <p>Aurae manages the <code>Spawn()</code> including the networking bridge, and service identity management transparently at runtime.</p> <p></p> <p>Note: In the case that virtualization is not available on the host (e.g. nested virtualization in the cloud), Aurae will spawn directly into an isolated Cell.</p>"},{"location":"blog/2022-10-24-aurae-cells/#virtual-machines-with-aurae","title":"Virtual Machines with Aurae","text":"<p>Because Aurae will have the capability to <code>Spawn()</code> itself using the KVM, it is also possible to expose raw virtual machine functionality for users who wish to leverage Aurae as a long-lived hypervisor as well. Because Aurae maintains its own concept of system state as well as all of the cells on a system it is possible to break up a single host in many ways, with many isolation possibilities. </p> <pre><code>  rpc RunVirtualMachine(VirtualMachine) returns (VirtualMachineStatus) {}\n</code></pre>"},{"location":"blog/2022-10-24-aurae-cells/#pods","title":"Pods","text":"<p>Finally, we have the vocabulary needed to explain how an Aurae pod is unique.</p> <p>An Aurae pod is a <code>Cell</code> running in a spawned Aurae <code>Instance</code>. </p> <pre><code>  rpc RunPod(Pod) returns (PodStatus) {}\n</code></pre> <p>First Aurae will spawn a new instance of itself. Next Aurae will bridge to the spawned instance, and establish connectivity as a client to the new instance. The parent will then run a cell in the newly spawned Aurae instance.</p> <p>Because Aurae is acts as a hypervisor this gives an operator the ability to mount network devices directly into the spawned instance, which can be referenced from the nested cell.</p> <p>We believe this pattern to be a more flexible, secure, and efficient pattern which can be leveraged in place of traditional sidecar style mesh networking that is often seen with service mesh projects such as Istio. </p> <p>From the original client's perspective scheduling a pod will feel natural, and will still expose basic fields such as OCI image, listen port, etc. Users can run a pod with Aurae, and the extra isolation layer should be transparent and free just by executing the <code>RunPod</code> gRPC function.</p> <p>Note: The project has decided not to support the Kubernetes Pod API directly at this layer of the stack.</p>"},{"location":"blog/2022-10-24-aurae-cells/#whats-next","title":"What's Next?","text":"<p>The project is under active development, and many of the features described in this blog are currently a work in progress.</p> <p>If you are interested in helping us work on these features please feel welcome to join the discord where we discuss our progress.</p> <p>If you are interested in contributing please see the getting involved documentation.</p> <p>If you are interested in finding areas to contribute please see our good first issues which are designed to be easy for a newcomer to pick up and get started with. </p> <p>f you are interested in discussing product opportunities, or venture funding we unfortunately are not taking these discussions at this time. Our intention is to keep Aurae free and community driven.</p> <p>Author: Kris N\u00f3va</p>"},{"location":"blog/2022-12-11-cgroups/","title":"Cgroups in Aurae","text":"<p>We need a way to map <code>processes</code> to <code>cgroups</code> or in Aurae parlance <code>executables</code> to <code>cells</code>. </p> <p>Given a cgroup <code>my-cell</code> and two nested processes:</p> <ul> <li><code>sleep 500</code> with the name <code>sleep-500</code></li> <li><code>sleep 60</code> with the name <code>sleep-60</code></li> </ul> <p>How do we identify which PID to send signals to if the user intends to start/stop either the <code>sleep-500</code> or the <code>sleep-60</code> process within the cell?</p>"},{"location":"blog/2022-12-11-cgroups/#research-with-systemd","title":"Research with Systemd","text":"<p>The way <code>systemd</code> manages this is by storing the Unit file contents in memory during the duration of the process. This is why <code>systemd daemon-reload</code> must be executed before changes to the current unit file are effective. The mapping of the configuration in the Unit file to the sub-processes is managed in memory.</p>"},{"location":"blog/2022-12-11-cgroups/#differences-from-systemd","title":"Differences from Systemd","text":"<p>We would like to be able to start and stop arbitrary processes within a given cell. We currently believe that systemd creates a cgroup for each service, and the only way to \"add\" nested processes to a cgroup is by restarting the service with a hook to launch the intended nested process.</p>"},{"location":"blog/2022-12-11-cgroups/#option-1-the-varrunauraecells-way","title":"Option 1) The \"/var/run/aurae/cells\" Way","text":"<p>We create a new directory upon starting the daemon called <code>/var/run/aurae/cells</code> that we assume ownership of. We bake in the initialization setup in the same way we manage <code>/var/run/aurae.sock</code>. </p> <p>For every cell that is allocated we also create a file:</p> <pre><code>/var/run/aurae/cells/my-cell\n</code></pre> <p>We use the pre_exec function to create a file descriptor for each nested process that points back to the cell file.  The children will store the file descriptors and not the parent.</p> <p>Author: Kris N\u00f3va</p>"},{"location":"community/","title":"Aurae Community","text":"<p>Welcome to The Aurae Runtime project.</p> <p>The project name is pronounced like the English word \"aura\" and is named after a minor Greek/Roman mythological deity, whose name means \"breeze\".</p> <p>Aurae is a Nivenly Foundation project and agrees to abide by the Nivenly covenant.</p>"},{"location":"community/#getting-involved","title":"Getting Involved","text":"<p>If you would like to get involved with Aurae development:</p> <ul> <li>Join our discord.</li> <li>Read the Nivenly Covenant which calls out the code of conduct.</li> <li>Read the Contribution Guidelines.</li> <li>Sign the CLA to begin contributing as an individual contributor.</li> </ul>"},{"location":"community/#what-is-aurae","title":"What is Aurae?","text":"<p>Aurae is an opinionated turing complete scripting language built for the enterprise. Think of it like TypeScript for infrastructure platforms.</p> <p>Auraed is the project core runtime daemon, auth and identity management system, and gRPC server that listens on a Unix domain socket.</p>"},{"location":"crate/static.files/SourceSerif4-LICENSE-3bb119e13b1258b7/","title":"SourceSerif4 LICENSE 3bb119e13b1258b7","text":"<p>Copyright 2014-2021 Adobe (http://www.adobe.com/), with Reserved Font Name 'Source'. All Rights Reserved. Source is a trademark of Adobe in the United States and/or other countries. Copyright 2014 - 2023 Adobe (http://www.adobe.com/), with Reserved Font Name \u2018Source\u2019. All Rights Reserved. Source is a trademark of Adobe in the United States and/or other countries.</p> <p>This Font Software is licensed under the SIL Open Font License, Version 1.1.</p> <p>This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL</p>"},{"location":"crate/static.files/SourceSerif4-LICENSE-3bb119e13b1258b7/#sil-open-font-license-version-11-26-february-2007","title":"SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007","text":"<p>PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others.</p> <p>The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives.</p> <p>DEFINITIONS \"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation.</p> <p>\"Reserved Font Name\" refers to any names specified as such after the copyright statement(s).</p> <p>\"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s).</p> <p>\"Modified Version\" refers to any derivative made by adding to, deleting, or substituting -- in part or in whole -- any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment.</p> <p>\"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software.</p> <p>PERMISSION &amp; CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions:</p> <p>1) Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself.</p> <p>2) Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user.</p> <p>3) No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users.</p> <p>4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission.</p> <p>5) The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software.</p> <p>TERMINATION This license becomes null and void if any of the above conditions are not met.</p> <p>DISCLAIMER THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.</p>"},{"location":"development-environments/","title":"Development Environments","text":"<p>In an effort to ease the process of getting started and contributing to the project, the community documents development environments that are expected to work. Please note, x86_64 architecture is currently the only officially supported target for running the Aurae Daemon (auared).</p> <ol> <li>Apple Silicon - CLion &amp; Parallels Desktop<ul> <li>Uses CLion and an Ubuntu VM via Parallels Desktop to provide a development environment with a GUI.</li> </ul> </li> <li>macOS - Lima<ul> <li>Uses an Ubuntu VM via Lima to provide a development environment with an optional mounted   unix socket for interacting with auread on the host machine.</li> </ul> </li> </ol>"},{"location":"development-environments/macOS/lima/","title":"Developing on macOS with Lima","text":"<p>This development guide is intended for any macOS system with any text editor or IDE.</p> <p>Lima is a virtual machine launcher, mainly built for macOS, that provides convenient mechanisms for interacting and configuring virtual machines out of the box.</p>"},{"location":"development-environments/macOS/lima/#setup","title":"Setup","text":"<ol> <li> <p>Install lima. You can find the instructions at Lima's Getting Started documentation</p> </li> <li> <p>Create an Ubuntu virtual machine. This command will walk you through the installation process:    <pre><code>$ limactl start --name aurae\n</code></pre></p> </li> <li> <p>SSH into your virtual machine    <pre><code>$ limactl shell aurae\n</code></pre></p> </li> <li> <p>Follow the aurae Building from Source instructions. You can edit either stop the virtual    machine, edit its configuration to create a writable mount of the source code directory from your host machine to the    guest, or copy the contents of the source code directory to <code>/tmp/lima</code>, e.g., <code>/tmp/lima/aurae</code></p> </li> <li> <p>[Optional] Mount the unix socket from the guest machine to the host machine. Lima provides a simple way to    configure this, but you first need to stop your virtual machine to edit its configuration:    <pre><code>$ limactl stop aurea\n</code></pre>    Now you can edit the config:    <pre><code>$ limactl edit aurea\n</code></pre>    And you can add a configuration like this to the bottom:    <pre><code>portForwards:\n- guestSocket: \"/var/run/aurae/aurae.sock\"\n  hostSocket: \"aurae.sock\"\n</code></pre>    Then start your virtual machine again and start auraed:    <pre><code>$ limactl start aurae\n$ limactl shell make auraed-start\n</code></pre>    In another shell copy the virtual machine's <code>~/.aurae</code> directory to your own:    <pre><code>$ limactl copy -r aurae:~/.aurae ~/.aurae\n</code></pre>    Edit the contents of <code>~/.aurae/config</code> to fit the requirements of your host machine. Now you can interact with aurae    from your host machine!</p> </li> <li> <p>[Optional] If you're tired of specifying the name you gave your virtual machine, you can export an environment    variable that <code>limactl</code> will use for the default, like so:    <pre><code>$ export LIMA_INSTANCE=aurae\n</code></pre></p> </li> </ol>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/","title":"Developing on Apple silicon with CLion and Parallels Desktop","text":"<p>This is a development environment setup guide that may be helpful for those on Apple silicon. There are likely improvements to be made, but the steps are purposefully overly \"hand hold-y\" and detailed to be useful to a wider audience.</p> <p>This guide assumes you are following it from top to bottom.</p>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/#environment","title":"Environment","text":"<p>The environment used when writing this guide:</p> <ul> <li>Processor: Apple M1</li> <li>operating system: macOS Ventura</li> <li>Virtualizer one of:<ul> <li>Parallels Desktop for Mac 18 Pro Edition<ul> <li>A Standard edition exists, and may be enough. Parallels offers a trial period.</li> </ul> </li> <li>UTM emulator/virtualizer<ul> <li>Free, though its performance is not guaranteed and may take more work for you </li> </ul> </li> </ul> </li> <li>Virtual Machine (VM) operating system: Ubuntu 22.04 ARM64 (available in the choice list when creating a VM in   Parallels)</li> <li>IDE: JetBrains CLion 2022.3<ul> <li>Visual Studio Code will likely work as well, but the steps for setup are not noted in this guide as of yet.</li> </ul> </li> </ul>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/#parallels-vm-setup","title":"Parallels VM Setup","text":"<ol> <li>Download and install Parallels Desktop for Mac</li> <li>Create a new VM (File -&gt; New -&gt; Download Ubuntu Linux -&gt; Continue)</li> <li>After the VM is installed and starts up, shut down the VM before logging in</li> <li>Open Parallels Control Center (Window -&gt; Control Center)</li> <li>Click the gear icon next to the VM to open the VM's Configuration menu to make the configuration to your preferences.    The following are mine:<ul> <li>Options -&gt; Sharing -&gt; Disable all but \"Share Mac volumes with Linux\"</li> <li>Options -&gt; Sharing -&gt; Disable \"Share Linux applications with Mac\"</li> <li>Hardware -&gt; Processors -&gt; 6 (Standard edition allows up to 4, which should be fine)</li> <li>Hardware -&gt; Memory -&gt; 16384 MB (16GB; Standard edition allows up to 8GB which should be fine)</li> <li>Graphics -&gt; More Space (scaling will be done in the VM)</li> </ul> </li> <li>Start the VM again and enter a password to set it. You may have some windows demanding your attention:<ul> <li>Parallels asking for the password to use <code>sudo</code> and install Parallels Tools. Enter your password. Once it is done   installing, it will start a countdown to restart the VM...click postpone, or be quick.</li> <li>Livepatch setup, which seems impossible to just close.<ul> <li>Continue -&gt; \"No, don't send system info\" (unless you want to) -&gt; Next -&gt; Next -&gt; Done</li> </ul> </li> </ul> </li> <li>Restart and log in again</li> <li>(Optional) Right click the desktop -&gt; Display Settings -&gt; Adjust to your preferences</li> <li>(Optional, still in Settings) Keyboard -&gt; View and Customize Shortcuts -&gt; Search for \"lock\" -&gt; Disable it so you    don't accidentally lock your VM every time you want to clear the terminal.</li> <li>(Optional, still in Settings) Power -&gt; Screen Blank -&gt; Never</li> <li>(Optional) Right click the desktop -&gt; Open in Terminal -&gt; Click the Hamburger menu button -&gt; Adjust to your     preferences. The following are mine:<ul> <li>General -&gt; Theme variant -&gt; Dark</li> <li>Unnamed -&gt; Colors -&gt; Text and Background Color -&gt; Set Built-in schemes = Solarized dark</li> <li>Unnamed -&gt; Colors -&gt; Palette -&gt; Set Built-in schemes = Solarized</li> </ul> </li> <li>Create an empty directory where the Aurae files will be synced. This guide assumes you will create it on the desktop     at <code>Desktop/aurae</code>.</li> <li>(Optional) Now might be a good time to snapshot the VM (feel free to do it at any other step)<ol> <li>Open Parallels Control Center (Window -&gt; Control Center)</li> <li>Right click your VM -&gt; Manage Snapshots -&gt; New -&gt; Set a name (\"Init\") -&gt; Ok</li> </ol> </li> </ol>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/#utm-setup","title":"UTM Setup","text":"<p>Do not do this if you're using Parallels. You only need one VM.</p> <ol> <li>Download and install UTM from releases https://github.com/utmapp/UTM/releases</li> <li>Download the Ubuntu ISO and create a new VM: https://docs.getutm.app/guides/ubuntu/</li> <li>I never got clipboard sharing working, just decided to SSH in and rely on my host system. <code>ip a | grep addr</code> to get the address and then regular <code>ssh username@ip</code> (and whatever extras you prefer to set)</li> <li>Set up shared drive: follow https://docs.getutm.app/guest-support/linux/#virtfs then<ul> <li>add this line to <code>/etc/fstab</code>:     <pre><code>share   [mount point]   9p  trans=virtio,version=9p2000.L,rw,_netdev,nofail 0   0\n</code></pre></li> <li>Mount share and fix permissions (does not modify the host files, just inside-VM settings. Preserved between restarts.):     <pre><code>sudo mount /share\nsudo chown 1000:1000 /share\n</code></pre></li> </ul> </li> </ol> <p>Everything else should proceed the same.</p>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/#clion-setup","title":"CLion Setup","text":"<ol> <li>Download and install CLion.<ul> <li>This is on your mac, not in the VM. We will use CLion's remote development features to connect to the VM.</li> </ul> </li> <li>Open the Aurae project in CLion</li> <li>Install plugins (CLion -&gt; Setting -&gt; Plugins)<ul> <li>Rust</li> <li>Protocol Buffers</li> <li>Deno</li> </ul> </li> <li>Restart the IDE to finish installing the plugins</li> <li>Activate the experimental Rust plugin features<ol> <li>Open CLion's \"search everywhere\" window (can be opened via magnifying glass in upper right corner)</li> <li>Search for and select \"Experimental Features\"</li> <li>Activate all options that start with \"org.rust\"</li> </ol> </li> <li>Setup remote development (CLion -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Development)<ol> <li>Click the + icon -&gt; SFTP -&gt; Enter a name (\"AuraeVM\")</li> <li>Connection -&gt; SSH configuration -&gt; click the \"...\"<ol> <li>Set Host to the IP address of the VM (Parallels -&gt; Devices -&gt; Network -&gt; an IP address should be listed)</li> <li>Set Username to \"parallels\"</li> <li>Set Password to your VM's password -&gt; select \"Save Password\" -&gt; de-select \"Parse config file ~/.ssh/config\"</li> <li>Clicking Test Connection should show a success message</li> <li>Select Ok, to close the menu (we will be back in Settings)</li> </ol> </li> <li>Connection -&gt; Root path -&gt; click Autodetect (my root path becomes \"/home/parallels\")</li> <li>Connection -&gt; Select \"Use Rsync for download/upload/sync\"</li> <li>Mappings -&gt; Local path -&gt; should be set to the path to the Aurae project on your mac</li> <li>Mappings -&gt; Deployment path -&gt; <code>Desktop/aurae</code> (the empty directory created in the VM)</li> <li>Excluded Paths -&gt; + -&gt; Local path -&gt; path to the \"target\" directory in the Aurae project directory on your mac</li> <li>Click apply to save the settings so far</li> </ol> </li> <li>Configure development options (CLion -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Development -&gt; Options)<ul> <li>The following options are selected:<ul> <li>Overwrite up-to-date files</li> <li>Preserve file timestamps</li> <li>Delete target items when source ones do not exist</li> <li>Create empty directories</li> <li>Prompt when overwriting or deleting local items</li> <li>Upload changed files automatically to the default server -&gt; Always</li> <li>Delete remote files when local are deleted</li> <li>Preserve original file permissions -&gt; No</li> <li>Warn when uploading over newer file -&gt; No</li> </ul> </li> </ul> </li> <li>Configure the default deployment server<ol> <li>Open CLion's \"search everywhere\" window (can be opened via magnifying glass in upper right corner)</li> <li>Search \"Show Default Deployment Server\" -&gt; set to \"On\"</li> <li>Click the now visible \"Remote Development\" on the bottom bar -&gt; Remote Development -&gt; AuraeVM</li> </ol> </li> <li>Upload the project to the VM<ol> <li>Open the Project window -&gt; right click the root of the project -&gt; Deployment -&gt; Upload to AuraeVM<ul> <li>Changed files should automatically be uploaded, based on our settings, but CLion seems to use save events to   trigger the upload. Manually triggering the upload like this should only be required when the project files   change without CLion realizing, such as when switching git branches</li> <li>Syncing only occurs from host to vm, but some files are generated on build. To sync from vm to host, open the   Project window -&gt; right click the root of the project -&gt; Deployment -&gt; Sync with Deployed to AuraeVM. (   Generated files should not be checked in.)</li> </ul> </li> </ol> </li> </ol>"},{"location":"development-environments/macOS/apple-silicon/clion-parallels/#back-to-the-vm-setting-up-aurae","title":"Back to the VM (setting up Aurae)","text":"<p>Some of these steps are documented at Building from Source. These steps are likely going to get out of sync with the actual dependencies in the project. The GHA build image manifest file is also a good source to see the project's dependencies.</p> <ol> <li>Check the <code>Desktop/aurae</code> directory, it should no longer be empty</li> <li>Install dependencies. In the terminal run...     <pre><code>sudo apt-get update;\nsudo apt-get install -y protobuf-compiler;\nsudo apt-get install -y musl-tools;\nsudo apt-get install -y build-essential;\nsudo apt-get install -y llvm-15-dev; # bpf-linker dependency\nsudo apt-get install -y libclang-15-dev; # bpf-linker dependency\n</code></pre></li> <li>Install rust:<ol> <li>Open the browser in the VM -&gt; https://rustup.rs -&gt; copy the command (this is an official    Rust project, so we trust the command)</li> <li>Run the command -&gt; Select option 1 (\"Proceed with installation (default)\") when prompted</li> <li>Either follow the onscreen instructions to update PATH or close and reopen the terminal</li> <li>Run <code>rustup target add aarch64-unknown-linux-musl</code></li> </ol> </li> <li>Install buf<ul> <li>Buf Installation Docs</li> <li>Homebrew is not an option</li> <li>Binary works<ol> <li>Open a terminal (the directory should not be in your <code>Desktop/aurae</code> directory; desktop is easiest)</li> <li>Run <code>touch buf.sh</code></li> <li>Run <code>vi buf.sh</code></li> <li>Copy + paste the code block on the buf website</li> <li>Hit ESC then \":wq\" to save and exit</li> <li>Run <code>sudo -E sh buf.sh</code></li> </ol> </li> </ul> </li> <li>Build and install Aurae (terminal must be in the <code>Desktop/aurae</code> directory)    <pre><code>make pki config;\nmake build;\n</code></pre></li> <li>auraed needs to be run using sudo (<code>sudo -E auraed</code>), but Ubuntu will not let you for security reasons<ul> <li>Option A: use the full path: <code>sudo -E [full path to auraed installed by cargo]</code></li> <li>Option B: remove the security<ul> <li>Run <code>sudo -E visudo</code></li> <li>Comment out the line \"Defaults secure_path=...\" by prefixing it with \"#\" (disables security)</li> <li>Save &amp; exit via Ctrl+x -&gt; Y -&gt; ENTER</li> </ul> </li> <li>Option C: ease the security<ul> <li>add the path of the directory where cargo installed auraed to the same line indicated in option B.</li> </ul> </li> </ul> </li> </ol>"},{"location":"stdlib/","title":"The Aurae Standard Library","text":"<p>The Aurae Standard Library (stdlib or \"the library\") is a set of remote functions grouped together into logical groups called subsystems.</p> <p>The library leverages protobuf as the source of truth for the types, names, and function signatures for the library.</p>"},{"location":"stdlib/#what-is-a-subsystem","title":"What is a subsystem?","text":"<p>A subsystem is a smaller and scoped subsection of the library composed of RPCs and services. Subsystems are similar to \"packages\" or \"modules\" in programming languages such as Rust. Kubernetes has API groups, and Linux itself has subsystems.</p> <p>Each subsystem is unique. Each subsystem is liable to come with its own guarantees, and expectations.</p> <p>In protobuf terms a subsystem is a group of remote procedure calls (RPCs) and services.</p>"},{"location":"stdlib/#what-are-resources","title":"What are resources?","text":"<p>Aurae is built on the concept of core resources that represent the main components of the system. Resources are like objects.</p> <p>For example, Aurae has the concept of an <code>Executable</code> resource which represents an executable workload similar to systemd's Unit.</p> <p>The core resources are intended to be fundamental and composable, similar to the objects and structures found in modern programming languages.</p> <p>Resources are defined directly in the corresponding protobuf definition and later generated into code for various languages. A resource's corresponding message should never be passed directly to, or received directly from an RPC.</p> <p>In protobuf terms a resource is a message.</p>"},{"location":"stdlib/#what-are-services","title":"What are services?","text":"<p>Services are a section of the API designed to be a way of grouping functionality together such that it can be enabled/disabled with authorization mechanisms.</p> <p>A service should be discreet in the terms of how it mutates the system. For example if a service starts, it should stop. If a service allocates, it should free. And so on.</p> <p>Services should be named after a resource or set of functionality around common resources. Services should follow the <code>service NameService</code> paradigm as defined in the style guide.</p> <p>For example the service that mutates a <code>Cell</code> should be called <code>CellService</code>.</p>"},{"location":"stdlib/#what-are-functions","title":"What are functions?","text":"<p>A function is a discreet piece of functionality designed to execute on the \"backend\", or directly by an Aurae Daemon server.</p> <p>The library is designed to be executed procedurally and quickly. Many function calls per second is a reasonable expectation for any client.</p> <p>In protobuf terms a function is a remote procedure call (RPC)</p>"},{"location":"stdlib/#api-definition-convention","title":"API Definition Convention","text":"<p>Generally follow this style guide in the <code>.proto</code> files.</p> <p>It is short, but the main points are:</p> <ul> <li>Files should be named <code>lower_snake_case.proto</code></li> <li>Files should be ordered in the following manner</li> </ul> <pre><code>// AURAE LICENSE HEADER\n\nsyntax = \"proto3\";\n\npackage lower_snake_case_package_name;\n\n// imports sorted alphabetically\nimport \"path/to/dependency.proto\";\nimport \"path/to/other.proto\";\n\n// file options\n\n// everything else\n</code></pre> <p>Generally follow these rules:</p> <ul> <li>Services should be named <code>UpperCamelCase</code> (aka PascalCase)</li> <li>Service methods should be named <code>UpperCamelCase</code></li> <li>Messages should be named <code>UpperCamelCase</code></li> <li>Field names, including <code>oneof</code> and extension names, should be <code>snake_case</code></li> <li><code>repeated</code> fields should have pluralized names</li> <li>Enums should be named <code>UpperCamelCase</code></li> <li>Enum variants should be <code>SCREAMING_SNAKE_CASE</code></li> <li>The zero value enum variants should have the suffix <code>_UNSPECIFIED</code></li> <li>Enums should NOT be nested, and their variants should be prefixed with the enum's name</li> </ul> <pre><code>enum FooBar {\n  FOO_BAR_UNSPECIFIED = 0;\n  FOO_BAR_FIRST_VALUE = 1;\n  FOO_BAR_SECOND_VALUE = 2;\n}\n</code></pre> <p>A notable exception to the public specification above is the Aurae project's preference for standardizing the objects that are used as the request and response messages.</p> <p>The traditional convention that is meant to reduce the likelihood of future breaking changes and ease the creation of macros for generating code:</p> <ul> <li>RPC methods (e.g., <code>StartWidget</code>) should have dedicated request and response messages named <code>StartWidgetResponse</code> and <code>StopWidgetResponse</code></li> <li>Objects (e.g., <code>Widget</code>) should be embedded directly into their corresponding <code>StartWidgetRequest</code>, <code>StopWidgetRequest</code>, etc style methods.</li> </ul> <p>When deciding how to represent something in the API where there is an existing lower-level API, for example in the case of cgroups, prefer to represent the fields as close to the lower-level API as possible.  While it may be more natural to represent a list of CPUs as a repeated int, we prefer to offer familiarity to those users who know the lower-level API.</p>"},{"location":"stdlib/v0/","title":"Protocol Documentation","text":""},{"location":"stdlib/v0/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>cells.proto</p> <ul> <li>Cell</li> <li>CellGraphNode</li> <li>CellServiceAllocateRequest</li> <li>CellServiceAllocateResponse</li> <li>CellServiceFreeRequest</li> <li>CellServiceFreeResponse</li> <li>CellServiceListRequest</li> <li>CellServiceListResponse</li> <li>CellServiceStartRequest</li> <li>CellServiceStartResponse</li> <li>CellServiceStopRequest</li> <li>CellServiceStopResponse</li> <li>CpuController</li> <li>CpusetController</li> <li>Executable</li> <li> <p>MemoryController</p> </li> <li> <p>CellService</p> </li> </ul> </li> <li> <p>discovery.proto</p> <ul> <li>DiscoverRequest</li> <li> <p>DiscoverResponse</p> </li> <li> <p>DiscoveryService</p> </li> </ul> </li> <li> <p>observe.proto</p> <ul> <li>GetAuraeDaemonLogStreamRequest</li> <li>GetAuraeDaemonLogStreamResponse</li> <li>GetPosixSignalsStreamRequest</li> <li>GetPosixSignalsStreamResponse</li> <li>GetSubProcessStreamRequest</li> <li>GetSubProcessStreamResponse</li> <li>LogItem</li> <li>Signal</li> <li> <p>Workload</p> </li> <li> <p>LogChannelType</p> </li> <li> <p>WorkloadType</p> </li> <li> <p>ObserveService</p> </li> </ul> </li> <li> <p>vms.proto</p> <ul> <li>DriveMount</li> <li>IPConfiguration</li> <li>RootDrive</li> <li>VirtualMachine</li> <li>VmServiceCreateRequest</li> <li>VmServiceCreateResponse</li> <li>VmServiceFreeRequest</li> <li>VmServiceFreeResponse</li> <li>VmServiceStartRequest</li> <li>VmServiceStartResponse</li> <li>VmServiceStopRequest</li> <li> <p>VmServiceStopResponse</p> </li> <li> <p>VmService</p> </li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"stdlib/v0/#cellsproto","title":"cells.proto","text":""},{"location":"stdlib/v0/#cell","title":"Cell","text":"<p>An isolation resource used to divide a system into smaller resource boundaries.</p> Field Type Label Description name string Resource parameters for control groups (cgroups) Build on the cgroups-rs crate. See examples cpu CpuController cpuset CpusetController memory MemoryController isolate_process bool Will isolate the process (and proc filesystem) from the host. Will unshare the pid, ipc, uts, and mount namespaces. The cgroup namespace is always unshared with the host. <p>Default: false | | isolate_network | bool |  | Will isolate the network from the host. Will unshare the net namespaces. The cgroup namespace is always unshared with the host.</p> <p>Default: false |</p> <p></p>"},{"location":"stdlib/v0/#cellgraphnode","title":"CellGraphNode","text":"Field Type Label Description cell Cell children CellGraphNode repeated"},{"location":"stdlib/v0/#cellserviceallocaterequest","title":"CellServiceAllocateRequest","text":"<p>An Aurae cell is a name given to Linux control groups (cgroups) that also includes a name, and special pre-exec functionality that is executed from within the same context as any executables scheduled.</p> <p>A cell must be allocated for every executable scheduled. A cell defines the resource constraints of the system to allocate for an arbitrary use case.</p> Field Type Label Description cell Cell A smaller resource constrained section of the system. <p></p>"},{"location":"stdlib/v0/#cellserviceallocateresponse","title":"CellServiceAllocateResponse","text":"<p>The response after a cell has been allocated.</p> Field Type Label Description cell_name string cgroup_v2 bool A bool that will be set to true if the cgroup was created with cgroup v2 controller. <p></p>"},{"location":"stdlib/v0/#cellservicefreerequest","title":"CellServiceFreeRequest","text":"<p>Used to remove or free a cell after it has been allocated.</p> Field Type Label Description cell_name string <p></p>"},{"location":"stdlib/v0/#cellservicefreeresponse","title":"CellServiceFreeResponse","text":"<p>Response after removing or freeing a cell.</p> <p></p>"},{"location":"stdlib/v0/#cellservicelistrequest","title":"CellServiceListRequest","text":""},{"location":"stdlib/v0/#cellservicelistresponse","title":"CellServiceListResponse","text":"Field Type Label Description cells CellGraphNode repeated"},{"location":"stdlib/v0/#cellservicestartrequest","title":"CellServiceStartRequest","text":"<p>A request for starting an executable inside of a Cell.</p> <p>This is the lowest level of raw executive functionality. Here you can define shell commands, and meta information about the command. An executable is started synchronously.</p> Field Type Label Description cell_name string optional executable Executable <p></p>"},{"location":"stdlib/v0/#cellservicestartresponse","title":"CellServiceStartResponse","text":"<p>The response after starting an executable within a Cell.</p> Field Type Label Description pid int32 Return a pid as an int32 based on the pid_t type in various libc libraries. <p></p>"},{"location":"stdlib/v0/#cellservicestoprequest","title":"CellServiceStopRequest","text":"<p>Request to stop an executable at runtime.</p> Field Type Label Description cell_name string optional executable_name string <p></p>"},{"location":"stdlib/v0/#cellservicestopresponse","title":"CellServiceStopResponse","text":""},{"location":"stdlib/v0/#cpucontroller","title":"CpuController","text":"<p>Docs: https://docs.kernel.org/admin-guide/cgroup-v2.html#cpu</p> Field Type Label Description weight uint64 optional Weight of how much of the total CPU time should this control group get. Note that this is hierarchical, so this is weighted against the siblings of this control group. <ul> <li> <p>Minimum: 1 * Maximum: 10_000 | | max | int64 | optional | In one period (1_000_000), how much can the tasks run.</p> </li> <li> <p>Minimum: 0</p> </li> </ul> <p>By default a cgroup has no limit, represented as the literal string \"max\". Not settings this field retains the default of no limit. | | period | uint64 | optional | The period is used as the scheduling slice. It interacts with max (see above) as a given workload will only run for max microseconds within period microseconds.</p> <ul> <li>Minimum: 0</li> </ul> <p>By default a cgroup has period 100000. |</p> <p></p>"},{"location":"stdlib/v0/#cpusetcontroller","title":"CpusetController","text":"<p>Docs: https://docs.kernel.org/admin-guide/cgroup-v2.html#cpuset</p> Field Type Label Description cpus string optional A comma-separated list of CPU IDs where the task in the control group can run. Dashes between numbers indicate ranges. mems string optional Same syntax as the cpus field of this structure, but applies to memory nodes instead of processors. <p></p>"},{"location":"stdlib/v0/#executable","title":"Executable","text":"<p>The most primitive workload in Aurae, a standard executable process.</p> Field Type Label Description name string command string description string <p></p>"},{"location":"stdlib/v0/#memorycontroller","title":"MemoryController","text":"<p>Docs: https://docs.kernel.org/admin-guide/cgroup-v2.html#memory-interface-files</p> Field Type Label Description min int64 optional Hard memory protection. If the memory usage of a cgroup is within its effective min boundary, the cgroup\u2019s memory won\u2019t be reclaimed under any conditions. If there is no unprotected reclaimable memory available, OOM killer is invoked. Above the effective min boundary (or effective low boundary if it is higher), pages are reclaimed proportionally to the overage, reducing reclaim pressure for smaller overages. NOTE: unused by aurae low int64 optional Best-effort memory protection. If the memory usage of a cgroup is within its effective low boundary, the cgroup\u2019s memory won\u2019t be reclaimed unless there is no reclaimable memory available in unprotected cgroups. Above the effective low boundary (or effective min boundary if it is higher), pages are reclaimed proportionally to the overage, reducing reclaim pressure for smaller overages. high int64 optional Memory usage throttle limit. This is the main mechanism to control memory usage of a cgroup. If a cgroup\u2019s usage goes over the high boundary, the processes of the cgroup are throttled and put under heavy reclaim pressure. NOTE: unused by aurae max int64 optional Memory usage hard limit. This is the final protection mechanism. If a cgroup\u2019s memory usage reaches this limit and can\u2019t be reduced, the OOM killer is invoked in the cgroup. Under certain circumstances, the usage may go over the limit temporarily. <p></p>"},{"location":"stdlib/v0/#cellservice","title":"CellService","text":"<p>Cells is the most fundamental isolation boundary for Aurae. A cell is an isolate set of resources of the system which can be used to run workloads.</p> <p>A cell is composed of a unique cgroup namespace, and unshared kernel namespaces.</p> Method Name Request Type Response Type Description Allocate CellServiceAllocateRequest CellServiceAllocateResponse Reserve requested system resources for a new cell. For cells specifically this will allocate and reserve cgroup resources only. Free CellServiceFreeRequest CellServiceFreeResponse Free up previously requested resources for an existing cell Start CellServiceStartRequest CellServiceStartResponse Start a new Executable inside of an existing cell. Can be called in serial to start more than one executable in the same cell. Stop CellServiceStopRequest CellServiceStopResponse Stop one or more Executables inside of an existing cell. Can be called in serial to stop/retry more than one executable. List CellServiceListRequest CellServiceListResponse <p></p> <p>Top</p>"},{"location":"stdlib/v0/#discoveryproto","title":"discovery.proto","text":""},{"location":"stdlib/v0/#discoverrequest","title":"DiscoverRequest","text":""},{"location":"stdlib/v0/#discoverresponse","title":"DiscoverResponse","text":"Field Type Label Description healthy bool version string"},{"location":"stdlib/v0/#discoveryservice","title":"DiscoveryService","text":"Method Name Request Type Response Type Description Discover DiscoverRequest DiscoverResponse Used to confirm that the host is running Aurae and to get some information including the version of Aurae that is running. <p>Top</p>"},{"location":"stdlib/v0/#observeproto","title":"observe.proto","text":""},{"location":"stdlib/v0/#getauraedaemonlogstreamrequest","title":"GetAuraeDaemonLogStreamRequest","text":""},{"location":"stdlib/v0/#getauraedaemonlogstreamresponse","title":"GetAuraeDaemonLogStreamResponse","text":"Field Type Label Description item LogItem"},{"location":"stdlib/v0/#getposixsignalsstreamrequest","title":"GetPosixSignalsStreamRequest","text":"<p>Request a stream of POSIX signals</p> Field Type Label Description workload Workload The workload to which te response will be scoped. If no workload is / specified, a stream of all POSIX signals on the host will be returned. <p></p>"},{"location":"stdlib/v0/#getposixsignalsstreamresponse","title":"GetPosixSignalsStreamResponse","text":"Field Type Label Description signal Signal"},{"location":"stdlib/v0/#getsubprocessstreamrequest","title":"GetSubProcessStreamRequest","text":"<p>TODO: not implemented in auraescript</p> Field Type Label Description process_id int32 channel_type LogChannelType <p></p>"},{"location":"stdlib/v0/#getsubprocessstreamresponse","title":"GetSubProcessStreamResponse","text":"Field Type Label Description item LogItem"},{"location":"stdlib/v0/#logitem","title":"LogItem","text":"Field Type Label Description channel string line string timestamp int64"},{"location":"stdlib/v0/#signal","title":"Signal","text":"Field Type Label Description signal int32 process_id int32"},{"location":"stdlib/v0/#workload","title":"Workload","text":"Field Type Label Description workload_type WorkloadType id string"},{"location":"stdlib/v0/#logchanneltype","title":"LogChannelType","text":"Name Number Description LOG_CHANNEL_TYPE_UNSPECIFIED 0 LOG_CHANNEL_TYPE_STDOUT 1 LOG_CHANNEL_TYPE_STDERR 2"},{"location":"stdlib/v0/#workloadtype","title":"WorkloadType","text":"Name Number Description WORKLOAD_TYPE_UNSPECIFIED 0 WORKLOAD_TYPE_CELL 1 WORKLOAD_TYPE_POD_SANDBOX 2 WORKLOAD_TYPE_VM 3"},{"location":"stdlib/v0/#observeservice","title":"ObserveService","text":"Method Name Request Type Response Type Description GetAuraeDaemonLogStream GetAuraeDaemonLogStreamRequest GetAuraeDaemonLogStreamResponse stream request log stream for aurae. everything logged via log macros in aurae (info!, error!, trace!, ... ). GetSubProcessStream GetSubProcessStreamRequest GetSubProcessStreamResponse stream TODO: request log stream for a sub process GetPosixSignalsStream GetPosixSignalsStreamRequest GetPosixSignalsStreamResponse stream request POSIX signals stream for the host <p>Top</p>"},{"location":"stdlib/v0/#vmsproto","title":"vms.proto","text":""},{"location":"stdlib/v0/#drivemount","title":"DriveMount","text":"Field Type Label Description host_path string The path on the host to the filesystem image or device that will be mounted inside the VM. vm_path string The path inside the VM guest at which the filesystem image or device will be mounted. fs_type string The filesystem type (i.e. ext4, xfs, etc.), as used when mounting the filesystem image inside the VM. The VM guest kernel is expected to have support for this filesystem. is_writeable bool Mount the root filesystem as read-write. (Default: false)"},{"location":"stdlib/v0/#ipconfiguration","title":"IPConfiguration","text":"<p>Static IP configuration for a VM network interface</p> Field Type Label Description primary_addr string PrimaryAddr specifies, in CIDR notation, the primary address and subnet that a network interface will be assigned inside the VM. gateway_addr string GatewayAddr specifies the default gateway that a network interface should use inside the VM. nameservers string repeated Nameservers is a list of nameservers that the VM will be configured to use internally <p></p>"},{"location":"stdlib/v0/#rootdrive","title":"RootDrive","text":"<p>Message to specify the block device config for a  VM</p> Field Type Label Description host_path string The path on the host to the filesystem image or device that will supply the rootfs of the VM. is_writeable bool Mount the root filesystem as read-write. (Default: false) <p></p>"},{"location":"stdlib/v0/#virtualmachine","title":"VirtualMachine","text":"<p>An Aurae virtual machine</p> Field Type Label Description id string The identifier of the VM mem_size_mb uint32 The memory size of VM vcpu_count uint32 The number of vCPUs for the VM kernel_img_path string The path to the VM kernel image kernel_args string repeated Arguments to pass to the kernel root_drive RootDrive Root drive config drive_mounts DriveMount repeated Additional drive mount configs <p></p>"},{"location":"stdlib/v0/#vmservicecreaterequest","title":"VmServiceCreateRequest","text":"Field Type Label Description machine VirtualMachine"},{"location":"stdlib/v0/#vmservicecreateresponse","title":"VmServiceCreateResponse","text":"Field Type Label Description vm_id string"},{"location":"stdlib/v0/#vmservicefreerequest","title":"VmServiceFreeRequest","text":""},{"location":"stdlib/v0/#vmservicefreeresponse","title":"VmServiceFreeResponse","text":"Field Type Label Description vm_id string"},{"location":"stdlib/v0/#vmservicestartrequest","title":"VmServiceStartRequest","text":"Field Type Label Description vm_id string"},{"location":"stdlib/v0/#vmservicestartresponse","title":"VmServiceStartResponse","text":""},{"location":"stdlib/v0/#vmservicestoprequest","title":"VmServiceStopRequest","text":"Field Type Label Description vm_id string"},{"location":"stdlib/v0/#vmservicestopresponse","title":"VmServiceStopResponse","text":""},{"location":"stdlib/v0/#vmservice","title":"VmService","text":"Method Name Request Type Response Type Description Create VmServiceCreateRequest VmServiceCreateResponse Reserve requested system resources for a new VM. Free VmServiceFreeRequest VmServiceFreeResponse Free up previously requested resources for an existing VM Start VmServiceStartRequest VmServiceStartResponse Start a new VM. Stop VmServiceStopRequest VmServiceStopResponse Stop one or more VMs."},{"location":"stdlib/v0/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"}]}